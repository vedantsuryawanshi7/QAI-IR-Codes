{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58c34fc-7596-41a1-a467-060232380560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b95dbf44-b0f6-4e23-b36e-138713dc0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'inform system '\n",
      "\n",
      "Documents retrieved:\n",
      "Document 4: Information retrieval systems are essential for search engines and data mining.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Preprocessing function for each document\n",
    "def preprocess_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text, language='english')\n",
    "    return [stemmer.stem(word) for word in words if word.lower() not in stop_words and word.isalpha()]\n",
    "\n",
    "# Step 2: Function to build the inverted index\n",
    "def build_inverted_index(documents):\n",
    "    inverted_index = defaultdict(list)  # Dictionary with a list of document IDs for each term\n",
    "    \n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        # Preprocess the document to get cleaned terms\n",
    "        processed_words = preprocess_text(doc)\n",
    "        # Update the inverted index: add doc_id to the list of documents for each word\n",
    "        for word in processed_words:\n",
    "            if doc_id not in inverted_index[word]:\n",
    "                inverted_index[word].append(doc_id)\n",
    "    \n",
    "    return inverted_index\n",
    "\n",
    "# Step 3: Function to retrieve documents based on query terms\n",
    "def retrieve_documents(query, inverted_index):\n",
    "    # Preprocess the query (similar to document preprocessing)\n",
    "    processed_query = preprocess_text(query)\n",
    "    \n",
    "    # Find documents containing all query terms\n",
    "    relevant_docs = []\n",
    "    for word in processed_query:\n",
    "        if word in inverted_index:\n",
    "            relevant_docs.append(set(inverted_index[word]))\n",
    "        else:\n",
    "            return []  # If any word in the query isn't in the index, return no results\n",
    "    \n",
    "    # Get the intersection of documents that contain all query words\n",
    "    result_docs = set.intersection(*relevant_docs)\n",
    "    return list(result_docs)\n",
    "\n",
    "# Step 4: Test the retrieval system with a sample set of documents and queries\n",
    "def main():\n",
    "    # Example set of documents (can be replaced by web-mined documents)\n",
    "    documents = [\n",
    "        \"Information retrieval is the process of retrieving relevant information.\",\n",
    "        \"Web mining is used to extract useful information from web documents.\",\n",
    "        \"The goal of data mining is to discover patterns in large datasets.\",\n",
    "        \"Retrieving web documents efficiently is a major focus in search engines.\",\n",
    "        \"Information retrieval systems are essential for search engines and data mining.\"\n",
    "    ]\n",
    "    \n",
    "    # Build the inverted index for the documents\n",
    "    inverted_index = build_inverted_index(documents)\n",
    "    \n",
    "    # Example query\n",
    "    query = \"inform system \"\n",
    "    \n",
    "    # Retrieve the documents matching the query\n",
    "    result_docs = retrieve_documents(query, inverted_index)\n",
    "    \n",
    "    # Evaluate and print the retrieved documents\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(\"Documents retrieved:\")\n",
    "    for doc_id in result_docs:\n",
    "        print(f\"Document {doc_id}: {documents[doc_id]}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a6282-e5b6-4b42-ac7a-3a7d6e130f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
